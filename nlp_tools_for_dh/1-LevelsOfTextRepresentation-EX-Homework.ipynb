{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework set 1: Levels of text representation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1: Documents\n",
    "\n",
    "2 points\n",
    "\n",
    "a) Following line reads the file \"kafka_metamorphosis.txt\", which is the beginning of Franz Kafka's [book Metamorphosis](https://www.gutenberg.org/cache/epub/5200/pg5200.txt). Tokenize the file into sentences with [Sentencizer](https://spacy.io/api/sentencizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x7f6d97175540>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"kafka_metamorphosis.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence for sentence in doc.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Calculate length of the sentence list and print the type of the first element of the sentence list with `type(sentences[0])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 21\n",
      "Type of the first element in sentences list: <class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "print('Number of sentences:', len(sentences))\n",
    "print('Type of the first element in sentences list:', type(sentences[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2: Bag of words\n",
    "\n",
    "3 points\n",
    "\n",
    "Install [Sklearn -library](https://scikit-learn.org/stable/install.html), which is a commonly used library for machine learning and text preprocessing. Sklearn provides an easy way to calculate bag-of-words representations of document's sentences. It requires the input to be a list of sentences, and we have that from previous exercise. \n",
    "\n",
    "a) Print bag-of-words matrix and feature names using [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) object's methods (hint: you need methods fit_transform(), get_feature_names() and toarray()). Save your result bag-of-words array to a list named **bow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'about', 'above', 'all', 'although', 'always', 'an', 'and', 'any', 'anyone', 'arches', 'arm', 'armour', 'as', 'at', 'back', 'bad', 'be', 'because', 'become', 'bed', 'bedding', 'before', 'began', 'belly', 'better', 'between', 'bit', 'boa', 'brown', 'business', 'but', 'by', 'can', 'career', 'chosen', 'cold', 'collection', 'compared', 'connections', 'contact', 'could', 'couldn', 'cover', 'covered', 'curse', 'cut', 'day', 'didn', 'different', 'divided', 'do', 'doing', 'domed', 'dream', 'dreams', 'drew', 'drops', 'dull', 'effort', 'eyes', 'familiar', 'feel', 'felt', 'fitted', 'floundering', 'food', 'forget', 'found', 'four', 'frame', 'friendly', 'from', 'fur', 'get', 'gilded', 'go', 'god', 'gregor', 'had', 'happened', 'hard', 'hardly', 'hat', 'have', 'he', 'head', 'headboard', 'heard', 'heavy', 'hell', 'helplessly', 'her', 'him', 'himself', 'his', 'hitting', 'home', 'horrible', 'housed', 'how', 'however', 'human', 'hundred', 'hung', 'if', 'illustrated', 'in', 'into', 'irregular', 'is', 'it', 'itch', 'its', 'know', 'lady', 'lay', 'legs', 'lift', 'lifted', 'like', 'little', 'longer', 'look', 'looked', 'lots', 'lower', 'made', 'magazine', 'make', 'making', 'many', 'me', 'mild', 'moment', 'more', 'morning', 'much', 'muff', 'must', 'never', 'nice', 'nonsense', 'of', 'off', 'oh', 'on', 'one', 'only', 'onto', 'or', 'out', 'overcome', 'own', 'pain', 'pane', 'peacefully', 'people', 'picture', 'pitifully', 'place', 'position', 'present', 'proper', 'pushed', 'quickly', 'quite', 'rain', 'raising', 'ready', 'recently', 'rest', 'right', 'rolled', 'room', 'sad', 'salesman', 'samples', 'samsa', 'sat', 'saw', 'sections', 'see', 'seemed', 'showed', 'shudder', 'shut', 'size', 'sleep', 'sleeping', 'slide', 'slight', 'slightly', 'slowly', 'small', 'so', 'something', 'soon', 'spots', 'spread', 'state', 'stiff', 'stopped', 'strenuous', 'table', 'takes', 'textile', 'than', 'that', 'the', 'them', 'then', 'there', 'thin', 'this', 'thought', 'threw', 'time', 'times', 'to', 'too', 'top', 'touched', 'towards', 'train', 'transformed', 'travelling', 'tried', 'troubled', 'turned', 'unable', 'up', 'upright', 'used', 've', 'vermin', 'viewer', 'walls', 'was', 'wasn', 'waved', 'weather', 'what', 'when', 'where', 'which', 'white', 'who', 'whole', 'window', 'with', 'woke', 'worries', 'wouldn', 'you', 'your']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "sentences = list(map(lambda x: str(x), sentences)) # Change Span objects to strings for the following analysis\n",
    "\n",
    "bow = cv.fit_transform(sentences).toarray()\n",
    "feature_names = cv.get_feature_names()\n",
    "\n",
    "print(feature_names)\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below adds sentencewise word counts into one list, which describes word counts in the whole document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentbow = [sum(y) for y in zip(*bow)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Get the occurrence count of word 'the' with first using list method [index](https://www.w3schools.com/python/ref_list_index.asp) for the feature name list and then accessing the bow-list in the given index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "the = feature_names.index('the')\n",
    "print(documentbow[the])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Get the occurrence count of word 'food'. You should verify the result that 'the' occurs multiple times more than 'food'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "food = feature_names.index('food')\n",
    "print(documentbow[food])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Find out, which word occurs most often in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n"
     ]
    }
   ],
   "source": [
    "most_often_index = documentbow.index((sorted(documentbow)[-1]))\n",
    "print(feature_names[most_often_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
